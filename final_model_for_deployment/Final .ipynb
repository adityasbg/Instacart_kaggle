{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import joblib\n",
    "import os \n",
    "import numpy as np\n",
    "from multipledispatch import dispatch\n",
    "from sklearn.metrics import f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_dictionary(filename):\n",
    "    '''\n",
    "    Load serialized dictionary\n",
    "    '''\n",
    "    with open(os.path.join(filename), 'rb') as handle:\n",
    "        file_dict = pickle.load(handle)\n",
    "        \n",
    "    return file_dict\n",
    "\n",
    "def deserialize_model( filename):\n",
    "    \"\"\"\n",
    "    DeSerialize trained model \n",
    "    \"\"\"\n",
    "    return joblib.load(filename)\n",
    "\n",
    "\n",
    "def standardize(X_train, X_test ,test_preprocessing_object , flag ='train'):\n",
    "    \"\"\"\n",
    "    This function standardize test and train columns if flag is train standization will fit and trainsform \n",
    "    if test it will just standardize.\n",
    "    returns train ,test and  test_preprocessing_object if flag is train else test data and test_preprocessing_object\n",
    "    X_train : train data\n",
    "    X_test  :test data \n",
    "    test_preprocessing_object : dictionary containing object of columns transformer for different column \n",
    "    flag : string either train or test \n",
    "    \"\"\"\n",
    "    std_columns =['ur_pr_reordered','order_number','ttl_cnt_product_user','Avg_no_prod_perOrder','days_since_prior_order','usr_ro_ratio','product_name_length']\n",
    "    scaler_objects =[]\n",
    "\n",
    "    if(flag == 'train'):\n",
    "        for col in std_columns:\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train.loc[:,col].values.reshape(-1,1))\n",
    "            X_train.loc[:,col] =scaler.transform(X_train.loc[:,col].values.reshape(-1,1))\n",
    "            X_test.loc[:,col] =scaler.transform(X_test.loc[:,col].values.reshape(-1,1))\n",
    "            scaler_objects.append({col:scaler})\n",
    "            del scaler\n",
    "            gc.collect()\n",
    "        test_preprocessing_object['std']=scaler_objects\n",
    "    elif(flag =='test'):\n",
    "        for item in test_preprocessing_object['std']:\n",
    "            for col_item in item.items():\n",
    "                col =col_item[0]\n",
    "                scaler=col_item[1]\n",
    "\n",
    "                X_test.loc[:,col] =scaler.transform(X_test.loc[:,col].values.reshape(-1,1))\n",
    "    if(flag=='train'):\n",
    "        return X_train.copy() , X_test.copy() ,test_preprocessing_object\n",
    "    else:\n",
    "        return X_test.copy() ,test_preprocessing_object\n",
    "            \n",
    "def response_code_test( X_test ,response_dict):\n",
    "    \"\"\"\n",
    "    This function takes data and does fit transform based on column wise,\n",
    "    according to column specific encoder stored in reponse_dctionary \n",
    "    X_test : test data \n",
    "    response_dict : dictionary containing encoder object \n",
    "    return transformed test data \n",
    "    \"\"\"\n",
    "\n",
    "    response_column =['max_hour_of_day' ,'reordered_last','max_dow']\n",
    "    for col in response_column:\n",
    "        encoder =response_dict[col]\n",
    "        X_test.loc[:,col] =encoder.transform(X_test.loc[:,col])\n",
    "\n",
    "\n",
    "    \n",
    "    return X_test.copy()\n",
    "\n",
    "\n",
    "def merge_products(x):\n",
    "    \"\"\"\n",
    "    x : string input\n",
    "    This function merge group to a list \n",
    "    returns list of strings \n",
    "    \"\"\"\n",
    "    return \" \".join(list(x.astype('str')))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestProduct(test_sub, pred , thresh):\n",
    "    \"\"\"\n",
    "    This suggests products based on if Prediction is reordered =1\n",
    "    \n",
    "    returns Dataframe containing order_id and group of product_id seperated by space \n",
    "    \n",
    "    test_sub : dataframe containing order_id and product_id\n",
    "    \n",
    "    pred:prediction probality of positive class\n",
    "    \n",
    "    thresh : optimal threshold to convert probality to class \n",
    "    \"\"\"\n",
    "    \n",
    "    # if pobality is greter than threshold predict 1 else 0\n",
    "    test_sub[\"Pred\"] = np.where(pred>=thresh ,1,0)\n",
    "    # select all cases where prediction is 1\n",
    "    test_sub = test_sub.loc[test_sub[\"Pred\"].astype('int')==1]\n",
    "    #group by order_id and create lsit of products\n",
    "    test_sub = test_sub.groupby(\"order_id\")[\"product_id\"].aggregate(merge_products).reset_index()\n",
    "    test_sub.columns = [\"order_id\", \"products\"]\n",
    "    \n",
    "\n",
    "    return test_sub['products'].values\n",
    "\n",
    "@dispatch(list,int)\n",
    "def validate_order_id( orderIds,id_):\n",
    "    \"\"\"\n",
    "    This function checks if querried order id is there in list of order_id\n",
    "    returns True is order id is present and false if not present\n",
    "    \"\"\"\n",
    "\n",
    "    flag =False\n",
    "    for order_id in orderIds:\n",
    "        if id_ == order_id:\n",
    "            flag=True\n",
    "            break       \n",
    "    return flag\n",
    "\n",
    "\n",
    "@dispatch(list,list)\n",
    "def validate_order_id( orderIds,id_list):\n",
    "\n",
    "    \"\"\"\n",
    "    This function returns list of valid order_id  querried by user\n",
    "    \"\"\"\n",
    "\n",
    "    valid_order_ids =[]\n",
    "    for querry_id in id_list:\n",
    "        for order_id in orderIds:\n",
    "            if order_id ==querry_id:\n",
    "                valid_order_ids.append(querry_id)\n",
    "                break\n",
    "      \n",
    "    return valid_order_ids\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(int)\n",
    "def final(orderNumber):\n",
    "    \"\"\"\n",
    "    This function takes orderNumber and suggest Product user is most Likely to buy\n",
    "    orderNumber :Integer\n",
    "    retruns : None or string of product Id seperated by space\n",
    "    \n",
    "    \"\"\"\n",
    "    # Read data set \n",
    "    test =pd.read_parquet('data/test.gzip')\n",
    "    # get all the order_id in dataset\n",
    "    orderIds =list(test.order_id.values)\n",
    "    product_suggestion ='None'\n",
    "    \n",
    "    # check if order If order Id querred is valid \n",
    "    if(validate_order_id( orderIds,orderNumber)):\n",
    "        # filter dataset based on orderId\n",
    "        test=test[test.order_id ==orderNumber]\n",
    "        \n",
    "        # store all the product user bought for particular order id\n",
    "        test_temp = test[[\"order_id\", \"product_id\"]]\n",
    "        \n",
    "        # drop unnecessarory columns  \n",
    "        test.drop(columns =[\"order_id\",'ur_pr_count' ,\"user_id\" ,'product_id' ,'department_id' ,'aisle_id' ,'ur_pr_count'] , inplace =True)\n",
    "        # standardizing test data \n",
    "        test_preprocessing_object= read_pickle_dictionary(os.path.join('final_model_pkl' ,'test_preprocessing_object_dict.pkl' ))\n",
    "        test , test_preprocessing_object=standardize(None, test ,test_preprocessing_object , flag ='test')\n",
    "        # Target code encodding\n",
    "        reponse_dict= read_pickle_dictionary(os.path.join('final_model_pkl' ,'reponse_dict.pkl' ))\n",
    "        test=response_code_test( test ,reponse_dict)\n",
    "        # read pickled  model for prediction \n",
    "        xgboost=deserialize_model('final_model_pkl/xgboost.pkl')\n",
    "        # predict probality\n",
    "        predict_xg_test =xgboost.predict_proba(test)[:,1]\n",
    "        # threshold for prediction\n",
    "        threshold=0.692886\n",
    "        product_name =suggestProduct(test_temp ,predict_xg_test ,threshold)\n",
    "        # if suggested product is not empty take that as suggested product else None\n",
    "        if(product_name.shape[0]>0):\n",
    "            product_suggestion =product_name[0]\n",
    "                  \n",
    "    return product_suggestion\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dispatch(list)\n",
    "def final(orderNumber_list):\n",
    "    \"\"\"\n",
    "    This function takes list orderNumber and return F1 score\n",
    "    orderNumber :list of integer \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "     # Read data set \n",
    "    train =pd.read_parquet('data/train.gzip')\n",
    "    # get all the order_id in dataset\n",
    "    orderIds =list(train.order_id.values)\n",
    "    \n",
    "\n",
    "    y_predicted_final =[]\n",
    "    y_orignal_final =[]\n",
    "    \n",
    "    # check if order If order Id querred is valid \n",
    "    validated_order_id=validate_order_id( orderIds,orderNumber_list)\n",
    "  \n",
    "    # filter dataset based on orderId\n",
    "    train=train.loc[train.order_id.isin(validated_order_id)]\n",
    "    # getting Y original value\n",
    "    y_orignal = train.reordered\n",
    "    y_orignal_final.extend(y_orignal)\n",
    "\n",
    "    # preparing train data\n",
    "    train.drop(columns =[\"order_id\",'ur_pr_count' ,\"user_id\" ,'product_id' ,'department_id' ,'aisle_id' ,'ur_pr_count' ,'reordered'] , inplace =True)\n",
    "    # standardizing train data \n",
    "\n",
    "    test_preprocessing_object= read_pickle_dictionary(os.path.join('final_model_pkl' ,'test_preprocessing_object_dict.pkl' ))\n",
    "    train , test_preprocessing_object=standardize(None, train ,test_preprocessing_object , flag ='test')\n",
    "    # Target code encodding\n",
    "    reponse_dict= read_pickle_dictionary(os.path.join('final_model_pkl' ,'reponse_dict.pkl' ))\n",
    "    train=response_code_test( train ,reponse_dict)\n",
    "\n",
    "    # read pickled  model for prediction \n",
    "    xgboost=deserialize_model('final_model_pkl/xgboost.pkl')\n",
    "    # predict probality\n",
    "    predict_xg_test =xgboost.predict_proba(train)[:,1]\n",
    "\n",
    "    threshold=0.692886\n",
    "    # threshold for prediction\n",
    "    y_predicted =np.where(predict_xg_test>=threshold ,1,0)\n",
    "    y_predicted_final.extend(y_predicted)\n",
    "\n",
    "\n",
    "    return  f1_score(y_orignal_final ,y_predicted_final)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. final method is overloaded <br>\n",
    "## final(int) - Take Order number and returns string which contains list of product_id seperarted by space <br>\n",
    "## final(list[int]) Take list of Order number and returns F1_score(y_true , y_pred) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test order id id mutually exclusive: set()\n"
     ]
    }
   ],
   "source": [
    "test =pd.read_parquet('data/test.gzip')\n",
    "orderIds_te =set(test.order_id.values)\n",
    "\n",
    "# Read data set \n",
    "train =pd.read_parquet('data/train.gzip')\n",
    "# get all the order_id in dataset\n",
    "orderIds_tr =set(train.order_id.values)\n",
    "\n",
    "print(\"Train and test order id id mutually exclusive:\",orderIds_te.intersection(orderIds_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final(int) \n",
    "#### Filter all the row based on order_id than pass data it through  standardization and Target encoding \n",
    "#### Load pickled model, make prediction \n",
    "#### For all the prediction that is marked 1 or reodered , use associated product_id as suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test data to get order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =pd.read_parquet('data/test.gzip')\n",
    "orderIds_te =list(set(test.order_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order id: [1884719] suggested product: 21137 19048 48679 46969 28986 9018  \n",
      "Order id: [2729022] suggested product: 13176 18963 34335 27548 28226 5120  \n",
      "Order id: [1381670] suggested product: 13176 7781 40310 15902 24759 1194 41488 29387  \n",
      "Order id: [2245252] suggested product: 24184 24852 22935 30406 22963  \n",
      "Order id: [2537860] suggested product: 42265 27398 43772 46069 48370 24713  \n",
      "Order id: [1138659] suggested product: 24852 8518 21616 35417  \n",
      "Order id: [2910428] suggested product: 13176 21137 22825 42265 24184 34126 47209 1025 24964 45007 19057 22963 24489 20574 20842 28289 10749 5015 19820 48110 34584 11193 18594 40064 44815 10337 18993 39676 36267  \n",
      "Order id: [2337867] suggested product: 39928 13176 27845 44449 49478 30492 25487 13776 9689  \n",
      "Order id: [98749] suggested product: 43154 13575  \n",
      "Order id: [2231023] suggested product: 28535 31506 4367 35163 13225  \n",
      "Order id: [1486478] suggested product: 21137 22298 22025  \n",
      "Order id: [892226] suggested product: 30908  \n",
      "Order id: [1297585] suggested product: 12276 23621  \n",
      "Order id: [1309597] suggested product: 13176 35951 27521 19660 14764 14462 37297 46863  \n",
      "Order id: [2244632] suggested product: 3513 39276  \n",
      "Order id: [745898] suggested product: 26209 24964  \n",
      "Order id: [2567764] suggested product: 24852 31334  \n",
      "Order id: [3399308] suggested product: 24852 45066 37766 39408 9076 23178 23322  \n",
      "Order id: [3239291] suggested product: 47766 9839 13176 45007 8174 22124 42768 16254 25837 46505 21511 24954 26105  \n",
      "Order id: [1596932] suggested product: 21903 7559 13176 21137 27156 30391 33000 49235 24964 27966 37646 45535 21376 26282 41950 43961 1463 5240 37158 42768 21616 44449 1090 5450 48171 5646 5785 33037 49131 32467 35383 38288 14477  \n"
     ]
    }
   ],
   "source": [
    "# randomly take 20 order id and make prediction\n",
    "for i in range(20):\n",
    "    order_id=np.random.choice(orderIds_te ,1)\n",
    "    print(\"Order id: {} suggested product: {}  \".format(order_id, final(int(order_id[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final([int]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using train data as test data does not have target value to calulate f1 score \n",
    "#### Filter all the row based on list of order_id than pass data it through  standardization and Target encoding \n",
    "#### Load pickled model, make prediction \n",
    "#### Use predicted and orignal target value to calculate f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order list :  [2279114, 2732458]\n",
      "F1_score(y_true , y_pred) :  0.35714285714285715\n",
      "Order list :  [337549, 355082]\n",
      "F1_score(y_true , y_pred) :  0.32\n",
      "Order list :  [989351, 164154, 1444993]\n",
      "F1_score(y_true , y_pred) :  0.44897959183673475\n",
      "Order list :  [1848007, 1964314, 254280, 583469]\n",
      "F1_score(y_true , y_pred) :  0.5\n",
      "Order list :  [58135]\n",
      "F1_score(y_true , y_pred) :  0.4\n",
      "Order list :  [276061]\n",
      "F1_score(y_true , y_pred) :  0.0\n",
      "Order list :  [74542, 754657]\n",
      "F1_score(y_true , y_pred) :  0.3333333333333333\n",
      "Order list :  [569915, 1327561, 1215855, 909335]\n",
      "F1_score(y_true , y_pred) :  0.22950819672131145\n",
      "Order list :  [3296061, 1353800, 888633]\n",
      "F1_score(y_true , y_pred) :  0.7368421052631577\n",
      "Order list :  [287761, 1883209, 3196189, 73765]\n",
      "F1_score(y_true , y_pred) :  0.1142857142857143\n",
      "Order list :  [830177, 779724]\n",
      "F1_score(y_true , y_pred) :  0.40625000000000006\n",
      "Order list :  [3248564, 3198252, 2187619]\n",
      "F1_score(y_true , y_pred) :  0.5783132530120482\n",
      "Order list :  [1740268, 3393288, 202476]\n",
      "F1_score(y_true , y_pred) :  0.5599999999999999\n",
      "Order list :  [1289220, 2480688, 1773265]\n",
      "F1_score(y_true , y_pred) :  0.2105263157894737\n",
      "Order list :  [1462016, 3079769]\n",
      "F1_score(y_true , y_pred) :  0.1818181818181818\n",
      "Order list :  [1977922]\n",
      "F1_score(y_true , y_pred) :  0.3636363636363636\n",
      "Order list :  [3031911, 367533, 2603018]\n",
      "F1_score(y_true , y_pred) :  0.4444444444444444\n",
      "Order list :  [832601, 1445911, 2939736]\n",
      "F1_score(y_true , y_pred) :  0.3333333333333333\n",
      "Order list :  [2147419, 162795]\n",
      "F1_score(y_true , y_pred) :  0.3157894736842105\n",
      "Order list :  [232454, 758924, 876339]\n",
      "F1_score(y_true , y_pred) :  0.41666666666666663\n"
     ]
    }
   ],
   "source": [
    "# Read data set \n",
    "train =pd.read_parquet('data/train.gzip')\n",
    "# get all the order_id in dataset\n",
    "orderIds_tr =list(set(train.order_id.values))\n",
    "\n",
    "# randomly take 20 order id and make prediction\n",
    "for i in range(20):\n",
    "    np.random.randint(1,5)\n",
    "    \n",
    "    order_ids=list(np.random.choice(orderIds_tr ,np.random.randint(1,5)))\n",
    "    print(\"Order list : \" ,order_ids)  \n",
    "    print(\"F1_score(y_true , y_pred) : \",final(order_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
